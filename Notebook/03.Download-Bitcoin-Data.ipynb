{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d75caaf-23b4-49e8-9432-1f3bc76a8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19629838-228d-4b51-ab84-42d6ae73cc0b",
   "metadata": {},
   "source": [
    "# Download Historical Bitcoin Price Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fedfb-6f57-4231-b198-83b22e92f220",
   "metadata": {},
   "source": [
    "## Download historical Bitcoin price data from the Coinbase API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f526bd-f509-4db9-899e-27d42e120d4b",
   "metadata": {},
   "source": [
    "We will retrieve Bitcoin price information through the Coinbase API, capturing granular historical data at a minute-by-minute resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de1674-c430-45b8-9b7a-29dc418eece6",
   "metadata": {},
   "source": [
    "### Key features:\n",
    "1. Downloads minute-by-minute Bitcoin price data\n",
    "2. Automatically handles API rate limits\n",
    "3. Includes error handling and retries\n",
    "4. Creates backup files automatically\n",
    "5. Adds additional time columns for easier analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32c6e0-764d-4a38-8965-d4852daf5f13",
   "metadata": {},
   "source": [
    "### Important notes:\n",
    "1. It's recommended to download data in smaller time periods (e.g., 1-2 days at a time) due to the large volume of minute data\n",
    "2. The code automatically pauses between requests to respect API rate limits\n",
    "3. Backup files are created for each download\n",
    "4. The code will retry up to 3 times on errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9af950-0057-4ce7-939b-4c9fcf761020",
   "metadata": {},
   "source": [
    "The resulting CSV file will contain the following columns:\n",
    "- timestamp: The exact time of the data point\n",
    "- open: Opening price\n",
    "- high: Highest price during the minute\n",
    "- low: Lowest price during the minute\n",
    "- close: Closing price\n",
    "- volume: Trading volume\n",
    "- date: Date part of the timestamp\n",
    "- time: Time part of the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2029a2cb-ee10-4abe-a25a-586295b75d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_historical_data_minutes(start_date, end_date, granularity = 60):\n",
    "    \"\"\"\n",
    "    Downloads historical data from Coinbase API at minute intervals\n",
    "    \n",
    "    Parameters:\n",
    "    start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "    end_date (str): End date in 'YYYY-MM-DD' format\n",
    "    granularity (int): Interval in seconds (60 = 1 minute)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with historical data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert dates to datetime objects\n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    # Base URL for API requests\n",
    "    base_url = \"https://api.exchange.coinbase.com\"\n",
    "    \n",
    "    # Empty list to store data\n",
    "    all_data = []\n",
    "    \n",
    "    # For minute data, we'll get data in 300-minute intervals\n",
    "    # to comply with API limitations\n",
    "    current_start = start\n",
    "    \n",
    "    while current_start < end:\n",
    "        # For minute data, we take smaller time windows\n",
    "        current_end = min(current_start + timedelta(minutes = 300), end)\n",
    "        \n",
    "        # Create URL for the request\n",
    "        endpoint = f\"/products/BTC-USD/candles\"\n",
    "        params = {\n",
    "            'start': current_start.isoformat(),\n",
    "            'end': current_end.isoformat(),\n",
    "            'granularity': granularity\n",
    "        }\n",
    "        \n",
    "        # Send request with retries on error\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                response = requests.get(f\"{base_url}{endpoint}\", params=params)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    all_data.extend(data)\n",
    "                    print(f\"Downloaded data from {current_start} to {current_end}\")\n",
    "                    break\n",
    "                elif response.status_code == 429:  # Too Many Requests\n",
    "                    print(\"API rate limit reached. Waiting 30 seconds...\")\n",
    "                    time.sleep(30)\n",
    "                else:\n",
    "                    print(f\"Request error: {response.status_code}\")\n",
    "                    time.sleep(5)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                time.sleep(5)\n",
    "            retry_count += 1\n",
    "        \n",
    "        # Wait between requests to avoid hitting rate limits\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Move to next period\n",
    "        current_start = current_end\n",
    "\n",
    "    if not all_data:\n",
    "        raise Exception(\"No data received from API!\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    \n",
    "    # Sort by time\n",
    "    df = df.sort_values('timestamp')\n",
    "    \n",
    "    # Add additional time columns for easier analysis\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    df['time'] = df['timestamp'].dt.time\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_data_with_backup(df, filename='bitcoin_historical_data.csv'):\n",
    "    \"\"\"\n",
    "    Saves data with a backup file\n",
    "    \"\"\"\n",
    "    # Save main file\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    # Create backup file with timestamp\n",
    "    backup_filename = f\"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{filename}\"\n",
    "    df.to_csv(backup_filename, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {filename}\")\n",
    "    print(f\"Backup created at {backup_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4214f474-ecfd-4bde-93e6-900aab9875d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data from 2024-11-01 00:00:00 to 2024-11-01 05:00:00\n",
      "Downloaded data from 2024-11-01 05:00:00 to 2024-11-01 10:00:00\n",
      "Downloaded data from 2024-11-01 10:00:00 to 2024-11-01 15:00:00\n",
      "Downloaded data from 2024-11-01 15:00:00 to 2024-11-01 20:00:00\n",
      "Downloaded data from 2024-11-01 20:00:00 to 2024-11-02 00:00:00\n",
      "\n",
      "Downloaded data information:\n",
      "Number of rows: 1445\n",
      "Time period: from 2024-11-01 00:00:00 to 2024-11-02 00:00:00\n",
      "Data saved to test_bitcoin_historical_data_1_year.csv\n",
      "Backup created at backup_20241205_001254_test_bitcoin_historical_data_1_year.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Start date in 'YYYY-MM-DD' format\n",
    "    start_date = '2024-11-01'\n",
    "    # End date in 'YYYY-MM-DD' format\n",
    "    end_date = '2024-11-02'  # For minute data, it's recommended to download smaller periods\n",
    "    \n",
    "    try:\n",
    "        # Download the data\n",
    "        btc_data = get_historical_data_minutes(start_date, end_date)\n",
    "        \n",
    "        # Display information about the data\n",
    "        print(\"\\nDownloaded data information:\")\n",
    "        print(f\"Number of rows: {len(btc_data)}\")\n",
    "        print(f\"Time period: from {btc_data['timestamp'].min()} to {btc_data['timestamp'].max()}\")\n",
    "\n",
    "        filename = 'test_bitcoin_historical_data_1_year.csv'\n",
    "        # Save the data\n",
    "        save_data_with_backup(btc_data, filename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
