best_xgb_model_params_adasyn = {
    'objective': 'multi:softmax',
    'num_class': 3,
    'eval_metric': ['mlogloss', 'merror'],  
    'max_depth': 5, 
    'learning_rate': 0.1973029586902305,
    'n_estimators': 484, 
    'subsample': 0.7340427472235935,
    'colsample_bytree': 0.6616484686036108, 
    'reg_alpha': 0.41095402631516176,
    'reg_lambda': 0.13636562300523927,
    'min_child_weight': 7,
    'verbosity': 1,
    'random_state': 42,
    'n_jobs': 10
}

#############################################################

Cross-Validated Metrics:
F1-Score (Macro): 0.4891 ± 0.0119
F1-Score (Weighted): 0.9892 ± 0.0021
Balanced Accuracy: 0.5705 ± 0.0270
Cohen's Kappa: 0.2334 ± 0.0194
Log Loss: 0.0331 ± 0.0065
ROC-AUC: 0.9844 ± 0.0029

F1-Score(Macro) with Best Params and TimeSplit: 0.4891

Scores with Best Params and TimeSplit:
f1_macro_scores: 0.4891
balanced_acc_scores: 0.5705
f1_weighted_scores: 0.9892
kappa_scores: 0.2334
log_loss_scores: 0.0331
roc_auc_scores: 0.9844

################################################################
classification_train_report_XGBoost_adasyn:                
   precision    recall  f1-score   support

           0       1.00      1.00      1.00    420626
           1       0.35      0.44      0.39      1040
           2       0.32      0.43      0.37      1194

    accuracy                           0.99    422860
   macro avg       0.56      0.62      0.59    422860
weighted avg       0.99      0.99      0.99    422860


classification_test_report_XGBoost_adasyn:                
   precision    recall  f1-score   support

           0       1.00      1.00      1.00    105186
           1       0.27      0.19      0.22       265
           2       0.18      0.20      0.19       264

    accuracy                           0.99    105715
   macro avg       0.48      0.46      0.47    105715
weighted avg       0.99      0.99      0.99    105715

F1-Score (Macro) final training: 0.4687

F1 score (macro) : [0.4687221882965152]

Classification report: 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    105186
           1       0.27      0.19      0.22       265
           2       0.18      0.20      0.19       264

    accuracy                           0.99    105715
   macro avg       0.48      0.46      0.47    105715
weighted avg       0.99      0.99      0.99    105715




