best_xgb_model_params_smote = {
    'objective': 'multi:softmax',
    'num_class': 3,
    'eval_metric': ['mlogloss', 'merror'],  
    'max_depth': 6, 
    'learning_rate': 0.17162175913961525,
    'n_estimators': 242, 
    'subsample': 0.8348051679887819,
    'colsample_bytree': 0.7924327976006224, 
    'reg_alpha': 0.524354759427542,
    'reg_lambda': 0.06677336125564388,
    'min_child_weight': 2,
    'verbosity': 1,
    'random_state': 42,
    'n_jobs': 10
}

############################################################

Cross-Validated Metrics:
F1-Score (Macro): 0.4879 ± 0.0008
F1-Score (Weighted): 0.9909 ± 0.0011
Balanced Accuracy: 0.5130 ± 0.0249
Cohen's Kappa: 0.2319 ± 0.0009
Log Loss: 0.0265 ± 0.0039
ROC-AUC: 0.9853 ± 0.0026

F1-Score(Macro) with Best Params and TimeSplit: 0.4879

Scores with Best Params and TimeSplit:
f1_macro_scores: 0.4879
balanced_acc_scores: 0.5130
f1_weighted_scores: 0.9909
kappa_scores: 0.2319
log_loss_scores: 0.0265
roc_auc_scores: 0.9853
###########################################################

classification_train_report_XGBoost_smote:               
   precision    recall  f1-score   support

           0       1.00      1.00      1.00    420626
           1       0.50      0.43      0.46      1040
           2       0.43      0.42      0.43      1194

    accuracy                           0.99    422860
   macro avg       0.64      0.62      0.63    422860
weighted avg       0.99      0.99      0.99    422860


classification_test_report_XGBoost_smote:                
    precision    recall  f1-score   support

           0       1.00      1.00      1.00    105186
           1       0.28      0.14      0.18       265
           2       0.24      0.17      0.20       264

    accuracy                           0.99    105715
   macro avg       0.50      0.43      0.46    105715
weighted avg       0.99      0.99      0.99    105715

F1-Score (Macro) final training: 0.4594

F1 score (macro) : [0.45940759767544054]

Classification report: 
     precision    recall  f1-score   support

           0       1.00      1.00      1.00    105186
           1       0.28      0.14      0.18       265
           2       0.24      0.17      0.20       264

    accuracy                           0.99    105715
   macro avg       0.50      0.43      0.46    105715
weighted avg       0.99      0.99      0.99    105715

